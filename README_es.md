# 100 documentos de lectura obligatoria de PNL

Esta es una lista de 100 documentos importantes sobre procesamiento del lenguaje natural (PNL) que los estudiantes e investigadores serios que trabajan en el campo probablemente deberían conocer y leer. Esta lista está compilada por [Masato Hagiwara] (http://masatohagiwara.net/). Agradezco cualquier comentario sobre esta lista.

Esta lista se basa originalmente en las respuestas a una pregunta de Quora que publiqué hace años: [¿Cuáles son los trabajos de investigación más importantes que todos los estudiantes de PNL deberían leer definitivamente?] (Https://www.quora.com/What-are-the -los-trabajos-de-investigación-más-importantes-que-todos-estudiantes-de-PNL-deberían-definitivamente-leer). Agradezco a todas las personas que contribuyeron a la publicación original.

Esta lista está lejos de ser completa u objetiva, y está evolucionando, ya que los documentos importantes se publican año tras año. Avíseme a través de [solicitudes de extracción] (https://github.com/mhagiwara/100-nlp-papers/pulls) y [cuestiones] (https://github.com/mhagiwara/100-nlp-papers/issues ) si falta algo.

Además, no intenté incluir enlaces a documentos originales, ya que es mucho trabajo mantener actualizados los enlaces muertos. Estoy seguro de que puede encontrar la mayoría (si no todos) de los documentos enumerados aquí a través de una sola búsqueda en Google por sus títulos.

Un documento no tiene que ser una conferencia revisada por pares / periódico para aparecer aquí. También incluimos documentos de estilo tutorial / encuesta y publicaciones de blog que a menudo son más fáciles de entender que los documentos originales.

## Aprendizaje automático

* Avrim Blum y Tom Mitchell: Combinación de datos etiquetados y no etiquetados con capacitación conjunta, 1998.

* John Lafferty, Andrew McCallum, Fernando C.N. Pereira: Campos aleatorios condicionales: modelos probabilísticos para segmentar y etiquetar datos de secuencia, ICML 2001.

* Charles Sutton, Andrew McCallum. Una introducción a los campos aleatorios condicionales para el aprendizaje relacional.

* Kamal Nigam, et al .: Clasificación de texto de documentos etiquetados y no etiquetados usando EM. Aprendizaje automático, 1999.

* Kevin Knight: Inferencia bayesiana con lágrimas, 2009.

* Marco Tulio Ribeiro et al .: "¿Por qué debería confiar en usted?": Explicando las predicciones de cualquier clasificador, KDD 2016.

## Modelos neuronales

* Richard Socher, et al .: Agrupación dinámica y despliegue de codificadores automáticos recursivos para la detección de paráfrasis, NIPS 2011.

* Ronan Collobert et al .: Procesamiento del lenguaje natural (casi) de Scratch, J. de Machine Learning Research, 2011.

* Richard Socher, et al .: Modelos profundos recursivos para la composicionalidad semántica sobre un banco de sentimientos, EMNLP 2013.

* Xiang Zhang, Junbo Zhao y Yann LeCun: redes convolucionales a nivel de caracteres para la clasificación de texto, NIPS 2015.

* Yoon Kim: Redes neuronales convolucionales para la clasificación de oraciones, 2014.

* Christopher Olah: Understanding LSTM Networks, 2015.

* Matthew E. Peters, et al .: Representaciones de palabras contextualizadas profundas, 2018.

* Jacob Devlin, et al .: BERT: Pre-entrenamiento de transformadores bidireccionales profundos para la comprensión del lenguaje, 2018.

## Agrupamiento e inclusión de palabras

* Peter F Brown, et al .: Modelos de lenguaje natural de n-gramas de clase, 1992.

* Tomas Mikolov, et al .: Estimación eficiente de las representaciones de palabras en el espacio vectorial, 2013.

* Tomas Mikolov, et al .: Representaciones distribuidas de palabras y frases y su composición, NIPS 2013.

* Quoc V. Le y Tomas Mikolov: Representaciones distribuidas de oraciones y documentos, 2014.

* Jeffrey Pennington, et al .: GloVe: Vectores globales para la representación de palabras, 2014.

* Ryan Kiros, et al .: Skip-Thought Vectors, 2015.

* Piotr Bojanowski, et al .: Enriquecimiento de vectores de palabras con información de subword, 2017.

## Modelos de tema

* Thomas Hofmann: indexación semántica latente probabilística, SIGIR 1999.

* David Blei, Andrew Y. Ng y Michael I. Jordan: Asignación de Dirichlet latente, J. Machine Learning Research, 2003.

## Modelado de idiomas

* Joshua Goodman: Un poco de progreso en el modelado de idiomas, Informe técnico de MSR, 2001.

* Stanley F. Chen y Joshua Goodman: An Empirical Study of Smoothing Techniques for Language Modeling, ACL 2006.

* Yee Whye Teh: Un modelo jerárquico de lenguaje bayesiano basado en los procesos de Pitman-Yor, COLING / ACL 2006.

* Yee Whye Teh: Una interpretación bayesiana de Kneser-Ney interpolado, 2006.

* Yoshua Bengio, et al .: A Neural Probabilistic Language Model, J. of Machine Learning Research, 2003.

* Andrej Karpathy: La irrazonable efectividad de las redes neuronales recurrentes, 2015.

* Yoon Kim, et al .: Modelos de lenguaje neuronal conscientes del carácter, 2015.

## Segmentación, etiquetado, análisis

* Donald Hindle y Mats Rooth. Ambigüedad estructural y relaciones léxicas, Lingüística computacional, 1993.

* Adwait Ratnaparkhi: un modelo de máxima entropía para el etiquetado de parte del discurso, EMNLP 1996.

* Eugene Charniak: un analizador inspirado en la máxima entropía, NAACL 2000.

* Michael Collins: Métodos de entrenamiento discriminativos para modelos ocultos de Markov: teoría y experimentos con algoritmos de perceptrón, EMNLP 2002.

* Dan Klein y Christopher Manning: análisis exacto no digitalizado, ACL 2003.

* Dan Klein y Christopher Manning: inducción basada en corpus de estructura sintáctica: modelos de dependencia y C
circunscripción, ACL 2004.

* Joakim Nivre y Mario Scholz: análisis de dependencia determinista del texto en inglés, COLING 2004.

* Ryan McDonald et al .: Análisis de dependencias no proyectivas utilizando algoritmos de árbol de expansión, EMNLP 2005.

* Daniel Andor et al .: Redes neuronales basadas en la transición globalmente normalizadas, 2016.

* Oriol Vinyals, et al .: Grammar as a Foreign Language, 2015.

## Etiquetado secuencial y extracción de información

* Marti A. Hearst: Adquisición automática de hipónimos de grandes corporaciones de texto, COLING 1992.

* Collins y Singer: Modelos sin supervisión para la clasificación de entidades con nombre, EMNLP 1999.

* Patrick Pantel y Dekang Lin, Discovering Word Senses from Text, SIGKDD, 2002.

* Mike Mintz et al .: Supervisión distante para la extracción de relaciones sin datos etiquetados, ACL 2009.

* Zhiheng Huang et al .: Modelos bidireccionales LSTM-CRF para etiquetado secuencial, 2015.

* Xuezhe Ma y Eduard Hovy: etiquetado de secuencia de extremo a extremo a través de LSTM-CNNs-CRF bidireccional, ACL 2016.

## Traducción automática y transliteración, modelos de secuencia a secuencia

* Peter F. Brown et al .: Un enfoque estadístico para la traducción automática, Lingüística computacional, 1990.

* Kevin Knight, Graehl Jonathan. Transliteración de máquina. Lingüística computacional, 1992.

* Dekai Wu: gramáticas de transducción de inversión y análisis bilingüe de corpus paralelos, lingüística computacional, 1997.

* Kevin Knight: A Statistical MT Tutorial Workbook, 1999.

* Kishore Papineni, et al .: BLEU: un método para la evaluación automática de la traducción automática, ACL 2002.

* Philipp Koehn, Franz J Och y Daniel Marcu: traducción estadística basada en frases, NAACL 2003.

* Philip Resnik y Noah A. Smith: La Web como un corpus paralelo, Lingüística computacional, 2003.

* Franz J Och y Hermann Ney: el enfoque de plantillas de alineación para la traducción automática estadística, la lingüística computacional, 2004.

* David Chiang. Un modelo jerárquico basado en frases para la traducción automática estadística, ACL 2005.

* Ilya Sutskever, Oriol Vinyals y Quoc V. Le: Secuencia a secuencia de aprendizaje con redes neuronales, NIPS 2014.

* Oriol Vinyals, Quoc Le: A Neural Conversation Model, 2015.

* Dzmitry Bahdanau, et al .: Neural Machine Translation by Jointly Learning to Align and Translate, 2014.

* Minh-Thang Luong, et al .: Enfoques efectivos para la traducción automática neuronal basada en la atención, 2015.

* Rico Sennrich et al .: Traducción automática neuronal de palabras raras con unidades de subpalabras. ACL 2016.

* Yonghui Wu, et al .: Sistema de traducción automática neuronal de Google: Reduciendo la brecha entre la traducción humana y la automática, 2016.

* Jonas Gehring, et al .: secuencia convolucional para el aprendizaje de secuencias, 2017.

* Ashish Vaswani, et al .: Atención es todo lo que necesitas, 2017.

## Resolución de Coreferencia

* Vincent Ng: Investigación supervisada de la coreferencia de la frase sustantiva: los primeros quince años, ACL 2010.

* Kenton Lee at al .: Resolución de Coreferencia Neural de extremo a extremo, EMNLP 2017.

## Resumen automático de texto

* Kevin Knight y Daniel Marcu: resumen más allá de la extracción de oraciones. Inteligencia Artificial 139, 2002.

* James Clarke y Mirella Lapata: Modelando la compresión con restricciones de discurso. EMNLP-CONLL 2007.

* Ryan McDonald: A Study of Global Inference Algorithms in Multi-Document Summarization, ECIR 2007.

* Wen-tau Yih et al .: Resumen de documentos múltiples maximizando palabras de contenido informativo. IJCAI 2007.

* Alexander M Rush, et al .: Un modelo de atención neuronal para el resumen de oraciones. EMNLP 2015.

## Respuesta a preguntas y comprensión de la máquina

* Pranav Rajpurkar et al .: SQuAD: 100,000 preguntas para la comprensión de texto por máquina. EMNLP 2015.

* Minjoon Soo et al .: Flujo de atención bidireccional para la comprensión de la máquina. ICLR 2015.

## Generación, aprendizaje por refuerzo

* Jiwei Li, et al .: Aprendizaje de refuerzo profundo para la generación de diálogos, EMNLP 2016.

* Marc’Aurelio Ranzato et al .: Entrenamiento de nivel de secuencia con redes neuronales recurrentes. ICLR 2016.

* Lantao Yu, et al .: SeqGAN: Redes Adversarias Generativas de Secuencia con Gradiente de Política, AAAI 2017.

## Aplicación de algoritmos evolutivos en PNL

* Lars Bungum, Bjorn Gamback et al: Algoritmos evolutivos en el procesamiento del lenguaje natural

* L. Araujo et al: Simbiosis de técnicas evolutivas y procesamiento estadístico del lenguaje natural, IEEE Transactions on Evolutionary Computation (Volumen: 8, Número: 1, febrero de 2004)

* Enrique Alba, Gabriel Luque, Lourdes Araujo et al: etiquetado de lenguaje natural con algoritmos genéticos, cartas de procesamiento de información

* O. Cordón, E. Herrera-Viedma, C. López-Pujalte, M. Luque, C. Zarco et al: Una revisión sobre la aplicación de la computación evolutiva a la recuperación de información, International Journal of Approximate Reasoning

* Bill Keller, Rudi Lutz et al: Inducción evolutiva de gramáticas libres de contexto estocástico, Inducción evolutiva de gramáticas libres de contexto estocástico

* Manish Sarkar, B. Yegnanarayana, Deepak Khemani et al: Un algoritmo de agrupamiento que utiliza un enfoque basado en la programación evolutiva, Pattern Recognition Letters
